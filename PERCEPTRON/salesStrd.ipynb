# 1 
# 1 LIGHTGBM + XGBOOST WITH HOLIDAY,WEEKENDS,... CRITEREIA...
#  ERR = 1.05


import pandas as pd
from sklearn.ensemble import RandomForestRegressor, VotingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from datetime import datetime

# Load the training data
train_data = main_train_data.copy()

# Convert the 'Region\Date' column to datetime format
train_data['Region\Date'] = pd.to_datetime(train_data['Region\Date'], format='%d-%m-%Y')

# Extract additional features from the date
train_data['DayOfWeek'] = train_data['Region\Date'].dt.dayofweek
train_data['Month'] = train_data['Region\Date'].dt.month
train_data['DayOfMonth'] = train_data['Region\Date'].dt.day  # Add day of the month

# Identify holidays (you can customize this based on your dataset)
holidays = ['2015-12-25', '2016-01-01']  # Adjust holidays for your dataset
train_data['IsHoliday'] = train_data['Region\Date'].dt.date.astype(str).isin(holidays)

# Find the minimum date from the training data
min_date_train = train_data['Region\Date'].min()

# Convert the 'Region\Date' column to numerical values (days since the starting date)
train_data['Region\Date'] = (train_data['Region\Date'] - min_date_train).dt.days

# Remove rows with NA values
train_data = train_data.dropna()

# Extract features (dates) and target variables (sales values)
X_train = train_data[['Region\Date', 'DayOfWeek', 'Month', 'DayOfMonth', 'IsHoliday']]
y_train_usa = train_data['USA']
y_train_germany = train_data['Germany']

# Create models
model_usa_xgb = XGBRegressor(n_estimators=8000, random_state=4042)
model_germany_xgb = XGBRegressor(n_estimators=8000,  random_state=4042)

model_usa_lgbm = LGBMRegressor(n_estimators=1000, random_state=421)
model_germany_lgbm = LGBMRegressor(n_estimators=1000, random_state=421)

model_usa = VotingRegressor([('xgb', model_usa_xgb), ('lgbm', model_usa_lgbm)])
model_germany = VotingRegressor([('xgb', model_germany_xgb), ('lgbm', model_germany_lgbm)])

# Fit the models
model_usa.fit(X_train, y_train_usa)
model_germany.fit(X_train, y_train_germany)

# Load the test data
test_data = pd.read_csv('/content/drive/MyDrive/2 lab Nit mca/4th sem/hackathon/OPTIMA HACKATHON/test.csv')

# Convert the 'Dates' column to datetime format
test_data['Region\Date'] = pd.to_datetime(test_data['Dates'], format='%d-%m-%Y')

# Extract additional features from the date
test_data['DayOfWeek'] = test_data['Region\Date'].dt.dayofweek
test_data['Month'] = test_data['Region\Date'].dt.month
test_data['DayOfMonth'] = test_data['Region\Date'].dt.day  # Add day of the month

# Identify holidays (you can customize this based on your dataset)
test_data['IsHoliday'] = test_data['Region\Date'].dt.date.astype(str).isin(holidays)

# Convert the 'Region\Date' column to numerical values (days since the starting date)
test_data['Region\Date'] = (test_data['Region\Date'] - min_date_train).dt.days

# Make predictions on the test set
test_data['USA'] = model_usa.predict(test_data[['Region\Date', 'DayOfWeek', 'Month', 'DayOfMonth', 'IsHoliday']])
test_data['Germany'] = model_germany.predict(test_data[['Region\Date', 'DayOfWeek', 'Month', 'DayOfMonth', 'IsHoliday']])

# Round the predicted values to a maximum of 9 decimal places
test_data['USA'] = test_data['USA'].round(9)
test_data['Germany'] = test_data['Germany'].round(9)

# Save the output to a CSV file without the 'Region\Date' column
test_data[['Dates', 'USA', 'Germany']].to_csv('test_output_last_attempt_lightgbm_xg_ver77.csv', index=False, date_format='%Y-%m-%d')

# Display the test data with predictions
test_data[['Dates', 'USA', 'Germany']]

from google.colab import files

# Download the file
files.download('test_output_last_attempt_lightgbm_xg_ver77.csv')












# 22222222222222222

# test_output_lightgbm_xgboost 1.42
# 2 lightgbm_xgboost nly,
# ERR = 1.42




import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

from sklearn.ensemble import RandomForestRegressor, VotingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split


train_data= main_train_data.copy()

train_data.head()
train_data.shape

test_data = pd.read_csv('/content/drive/MyDrive/2 lab Nit mca/4th sem/hackathon/OPTIMA HACKATHON/test.csv')
main_test_data = test_data.copy()
test_data.shape
test_data.head()
test_data.shape



train_data.shape


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, VotingRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error



# Convert the 'Region\Date' column to datetime format
train_data['Region\Date'] = pd.to_datetime(train_data['Region\Date'], format='%d-%m-%Y')

# Find the minimum date from the training data
min_date_train = train_data['Region\Date'].min()

# Convert the 'Region\Date' column to numerical values (days since the starting date)
train_data['Region\Date'] = (train_data['Region\Date'] - min_date_train).dt.days




# Remove rows with NA values
train_data = train_data.dropna()



# Extract features (dates) and target variables (sales values)
X_train = train_data[['Region\Date']]
y_train_usa = train_data['USA']
y_train_germany = train_data['Germany']

# Extract features (dates) and target variables (sales values)
X_train = train_data[['Region\Date']]
y_train_usa = train_data['USA']
y_train_germany = train_data['Germany']




# Create XGBoost models
model_usa_xgb = XGBRegressor(n_estimators=800, random_state=42)
model_germany_xgb = XGBRegressor(n_estimators=800, random_state=42)

# Create a Voting Regressor for USA
model_usa = VotingRegressor([('rf', RandomForestRegressor(n_estimators=800, random_state=42)),
                              ('xgb', model_usa_xgb)])

# Create a Voting Regressor for Germany
model_germany = VotingRegressor([('rf', RandomForestRegressor(n_estimators=800, random_state=42)),
                                  ('xgb', model_germany_xgb)])

# Fit the models
model_usa.fit(X_train, y_train_usa)
model_germany.fit(X_train, y_train_germany)






# Convert the 'Dates' column to datetime format
test_data['Region\Date'] = pd.to_datetime(test_data['Dates'], format='%d-%m-%Y')

# Convert the 'Region\Date' column to numerical values (days since the starting date)
test_data['Region\Date'] = (test_data['Region\Date'] - min_date_train).dt.days

# Make predictions on the test set
test_data['USA'] = model_usa.predict(test_data[['Region\Date']])
test_data['Germany'] = model_germany.predict(test_data[['Region\Date']])





# Round the predicted values to a maximum of 9 decimal places
test_data['USA'] = test_data['USA'].round(9)
test_data['Germany'] = test_data['Germany'].round(9)

# Save the output to a CSV file without the 'Region\Date' column
test_data[['Dates', 'USA', 'Germany']].to_csv('test_output_xgboost_rf.csv', index=False, date_format='%Y-%m-%d')

# Display the test data with predictions
test_data[['Dates', 'USA', 'Germany']]

from google.colab import files

# Download the file
files.download('test_output_xgboost_rf.csv')
